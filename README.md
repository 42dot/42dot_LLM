<!--
## ëª©ì°¨
- [ì±—ë² ì´ì»¤ (ChatBaker)](#ì±—ë² ì´ì»¤-chatbaker)
  - [ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸](#ìƒì„±í˜•-ì–¸ì–´-ëª¨ë¸)
    - [í•™ìŠµ ë°ì´í„°ì…‹](#í•™ìŠµ-ë°ì´í„°ì…‹)
    - [í‰ê°€](#í‰ê°€)
  - [ì‚¬ì „ í•™ìŠµ ëª¨ë¸ (PLM)](#ì‚¬ì „-í•™ìŠµ-ëª¨ë¸-plm)
    - [ì•„í‚¤í…ì³](#ì•„í‚¤í…ì³)
    - [í•™ìŠµ](#í•™ìŠµ)
    - [í•™ìŠµ ë°ì´í„°ì…‹](#í•™ìŠµ-ë°ì´í„°ì…‹-1)
    - [í† í¬ë‚˜ì´ì €](#í† í¬ë‚˜ì´ì €)
    - [Zero-shot ì„±ëŠ¥ í‰ê°€](#zero-shot-ì„±ëŠ¥-í‰ê°€)
      - [í•œêµ­ì–´](#í•œêµ­ì–´)
      - [ì˜ì–´](#ì˜ì–´)
    - [ëª¨ë¸ ê³µê°œ](#ëª¨ë¸-ê³µê°œ)
  - [ì‚¬ìš©ë²•](#ì‚¬ìš©ë²•)
  - [í•œê³„ì ](#í•œê³„ì )
  - [ë¼ì´ì„¼ìŠ¤](#ë¼ì´ì„¼ìŠ¤)
  - [ìœ ì˜ì‚¬í•­](#ìœ ì˜ì‚¬í•­)
  - [Citation](#citation)
-->

<img src="asset/42dot.png" width="25%" height="25%" /><img src="asset/tagline.png" width="25%" height="25%" /><img src="asset/asterisk.png" width="10%" height="10%" />

# ì±—ë² ì´ì»¤ (ChatBaker)

**ì±—ë² ì´ì»¤** (**ChatBaker**)ëŠ” [**42dot**](https://42dot.ai/)ì—ì„œ ìì²´ ê°œë°œí•œ ì–¸ì–´ ëª¨ë¸ì˜ ëª…ì¹­ìœ¼ë¡œ, ë‹¤ìŒì˜ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
- ëŒ€í•œë¯¼êµ­ ê¸°ê´€ ìµœì´ˆì˜ **í•œì˜í†µí•© ì–¸ì–´ ëª¨ë¸ (=ChatBaker-PLM)** ê³µê°œ [more](#ì‚¬ì „-í•™ìŠµ-ëª¨ë¸-plm)
- ChatBaker-PLM ê¸°ë°˜ì˜ **ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸ (=ChatBaker-SFT)** ê³µê°œ [more](#ìƒì„±í˜•-ì–¸ì–´-ëª¨ë¸)
- ì§ì ‘ êµ¬ì¶•í•œ (ìˆ˜ì§‘, ì •ì œ) ë°ì´í„°, ìì²´ í•™ìŠµ ì¸í”„ë¼ ì‚¬ìš©

ë¿ë§Œì•„ë‹ˆë¼, [ğŸ¤—ChatBaker-PLM 1.3B](í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ í˜ì´ì§€ ë§í¬)]ì™€ [ğŸ¤—ChatBaker-SFT 1.3B](í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ í˜ì´ì§€ ë§í¬)]ë¥¼ ê³µê°œí–ˆìŠµë‹ˆë‹¤.


<figure align="center">
<img src="asset/ChatBaker.gif" width="80%" height="80%" />
<figcaption><b>ChatBaker-SFTì˜ example_cli.py ì‹¤í–‰ ì˜ˆì œ</b></figcaption>
</figure>


## ChatBaker-PLM (ì‚¬ì „ í•™ìŠµ ëª¨ë¸)
### ì•„í‚¤í…ì³
ChatBaker-PLMì€ [LLaMA 2](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/) ì™€ ìœ ì‚¬í•œ Transformer decoder ì•„í‚¤í…ì³ë¥¼ ì‚¬ìš©í–ˆê³ , ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| Params | Layers | Attention heads | Hidden size | FFN size |
| -- | -- | -- | -- | -- |
| 1.3B | 24 | 32 | 2,048 | 5,632 |

í•™ìŠµ ì„¸íŒ…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| Params | Global batch size\* | Initial learning rate | Train iter.\* | Max length\* | Weight decay |
| -- | -- | -- | -- | -- | -- |
| 1.3B | 4.0M | 4E-4 | 1.0T | 2K | 0.1 |

(\* ë‹¨ìœ„: tokens)

### í•™ìŠµ

ChatBaker-PLMì˜ í•™ìŠµì€ NVIDIA A100 80G 256ì¥ì„ ì‚¬ìš©í–ˆê³ , í•™ìŠµì— ì†Œìš”ëœ ì‹œê°„ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| Model | ChatBaker-PLM |
| -- | -- |
| Training time (approx.) | 6 days |


### í•™ìŠµ ë°ì´í„°ì…‹
ChatBaker-PLMì˜ í•™ìŠµ ë°ì´í„°ëŠ” ëª¨ë‘ ì›¹ ìƒì— ê³µê°œëœ ë°ì´í„°ë¥¼ ì´ìš©í•´ ì§„í–‰í–ˆê³ , ê·¸ êµ¬ì„±ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.
- í•œêµ­ì–´: ì•½ 100B í† í°
  - [ì§ì§€ í”„ë¡œì íŠ¸](http://jikji.duckdns.org/), [mC4](https://huggingface.co/datasets/mc4), [LBox Open](https://github.com/lbox-kr/lbox-open), [KLUE](https://huggingface.co/datasets/klue), [ìœ„í‚¤í”¼ë””ì•„ (í•œêµ­ì–´)](https://ko.wikipedia.org/) ë“± í¬í•¨
- ì˜ì–´: ì•½ 1.3T í† í°
  - [The Pile](https://github.com/EleutherAI/the-pile), [RedPajama](https://github.com/togethercomputer/RedPajama-Data), [C4](https://huggingface.co/datasets/c4) ë“± í¬í•¨

### í† í¬ë‚˜ì´ì €
Byte-level BPE í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í–ˆê³ , í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ 1,000ë§Œê±´ì˜ ë¬¸ì„œë¥¼ ìƒ˜í”Œë§í•´ í•™ìŠµí–ˆìŠµë‹ˆë‹¤. Vocaburaly í¬ê¸°ëŠ” ì•½ 50K ì…ë‹ˆë‹¤.

### Zero-shot ì„±ëŠ¥ í‰ê°€
ChatBaker-PLM ë° ë¹„ìŠ·í•œ íŒŒë¼ë¯¸í„° í¬ê¸°ì˜ íƒ€ PLMê³¼ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•´ í•œêµ­ì–´ ë° ì˜ì–´ Zero-shot ë²¤ì¹˜ë§ˆí¬ë¥¼ ì§„í–‰í–ˆê³ , ì•„ë˜ì˜ í‰ê°€ê²°ê³¼ëŠ” [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/polyglot)ë¥¼ ì´ìš©í•´ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.
#### í•œêµ­ì–´
- ë¹„êµëŒ€ìƒ:
  - [Polyglot-Ko 1.3B](https://github.com/EleutherAI/polyglot): [GPT-NeoX](https://github.com/EleutherAI/gpt-neox) ì•„í‚¤í…ì³ë¡œ í•œêµ­ì–´ 213B í† í° (863 GB)ì„ í•™ìŠµí•œ ëª¨ë¸
  - [KoGPT2 1.2B](https://github.com/SKT-AI/KoGPT2): GPT ì•„í‚¤í…ì³ë¡œ 40GB ì´ìƒì˜ í•œêµ­ì–´ ë°ì´í„°ì…‹ì„ í•™ìŠµí•œ ëª¨ë¸
  - [XGLM 1.7B](https://huggingface.co/facebook/xglm-1.7B): [GPT-3](https://arxiv.org/abs/2005.14165) ì•„í‚¤í…ì³ë¡œ í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 30ê°œ êµ­ì–´, 500B í† í°ì„ í•™ìŠµí•œ ëª¨ë¸
  - [PolyLM 1.7B](https://huggingface.co/DAMO-NLP-MT/polylm-1.7b): LLaMA ì•„í‚¤í…ì²˜ë¡œ í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 18ê°œ êµ­ì–´, 640B í† í°ì„ í•™ìŠµí•œ ëª¨ë¸
- í‰ê°€ ë°ì´í„°ì…‹:
  - [KoBEST](https://huggingface.co/datasets/skt/kobest_v1): BoolQ, COPA, HellaSwag, SentiNeg, WiCì˜ 5ê°œ íƒœìŠ¤í¬

<figure align="center">
<img src="asset/plm_benchmark_ko.png" width="90%" height="90%"/>
<figcaption><b>ChatBaker-PLMì˜ í•œêµ­ì–´ ì„±ëŠ¥</b></figcaption>
</figure>

|Tasks / Macro-F1|[KoGPT2](https://github.com/SKT-AI/KoGPT2) <br>1.2B|[Polyglot-Ko](https://github.com/EleutherAI/polyglot) <br>1.3B|[XGLM](https://huggingface.co/facebook/xglm-1.7B) <br>1.7B|[PolyLM](https://huggingface.co/DAMO-NLP-MT/polylm-1.7b) <br>1.7B|ChatBaker-PLM <br>1.3B|
|--------------|-----------|----------------|---------|-----------|------------------------|
|boolq         |0.337      |0.355           |**0.502**    |0.334      |0.424                   |
|copa          |0.67       |**0.721**           |0.616    |0.513      |0.698                   |
|hellaswag     |0.404      |0.401           |0.374    |0.321      |**0.438**                   |
|sentineg      |0.606      |0.679           |0.46     |0.382      |**0.74**                   |
|wic           |0.328      |0.328           |0.328    |0.328      |0.328                   |
|**average**       |0.469      |0.497           |0.456    |0.376      |**0.526**                   |

#### ì˜ì–´
- ë¹„êµëŒ€ìƒ:
  - [OPT 1.3B](https://huggingface.co/facebook/opt-1.3b): GPT-3 ì•„í‚¤í…ì³ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ì–´ 300B í† í° ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸
  - [MPT 1B](https://huggingface.co/mosaicml/mpt-1b-redpajama-200b): [MPT](https://www.mosaicml.com/blog/mpt-7b) ì•„í‚¤í…ì³ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RedPajama ë°ì´í„°ì— 200B í† í° í•™ìŠµí•œ ëª¨ë¸
  - XGLM 1.7B
  - PolyLM 1.7B

<figure align="center">
<img src="asset/plm_benchmark_en.png" width="90%" height="90%"/>
<figcaption><b>ChatBaker-PLMì˜ ì˜ì–´ ì„±ëŠ¥</b></figcaption>
</figure>

| Tasks / Metric         | MPT <br>1B | OPT <br>1.3B | XGLM <br>1.7B | PolyLM <br>1.7B | ChatBaker-PLM <br>1.3B |
| ---------------------- | ------ | -------- | --------- | ----------- | ------------------------ |
| anli_r1/acc            | 0.309  | **0.341**    | 0.334     | 0.336       | 0.303                    |
| anli_r2/acc            | 0.334  | **0.339**    | 0.331     | 0.314       | 0.337                    |
| anli_r3/acc            | 0.33   | 0.336    | 0.333     | **0.339**       | 0.328                    |
| arc_challenge/acc      | 0.268  | 0.234    | 0.21      | 0.198       | **0.287**                    |
| arc_challenge/acc_norm | 0.291  | 0.295    | 0.243     | 0.256       | **0.319**                     |
| arc_easy/acc           | 0.608  | 0.571    | 0.537     | 0.461       | **0.617**                    |
| arc_easy/acc_norm      | **0.555**  | 0.51     | 0.479     | 0.404       | 0.548                    |
| boolq/acc              | 0.517  | 0.578    | 0.585     | 0.617       | **0.62**                  |
| hellaswag/acc          | **0.415**  | **0.415**    | 0.362     | 0.322       | 0.412                    |
| hellaswag/acc_norm     | 0.532  | **0.537**    | 0.458     | 0.372       | 0.527                    |
| openbookqa/acc         | **0.238**  | 0.234    | 0.17      | 0.166       | 0.212                    |
| openbookqa/acc_norm    | **0.334**  | **0.334**    | 0.298     | **0.334**       | 0.328                    |
| piqa/acc               | 0.714  | **0.718**    | 0.697     | 0.667       | 0.711                    |
| piqa/acc_norm          | 0.72   | **0.724**    | 0.703     | 0.649       | 0.721                    |
| record/f1              | 0.84   | **0.857**    | 0.775     | 0.681       | 0.841                    |
| record/em              | 0.832  | **0.849**    | 0.769     | 0.674       | 0.834                    |
| rte/acc                | 0.541  | 0.523    | **0.559**     | 0.513       | 0.524                    |
| truthfulqa_mc/mc1      | 0.224  | 0.237    | 0.215     | **0.251**       | 0.247                    |
| truthfulqa_mc/mc2      | 0.387  | 0.386    | 0.373     | **0.428**       | 0.392                    |
| wic/acc                | 0.498  | **0.509**    | 0.503     | 0.5         | 0.502                    |
| winogrande/acc         | 0.574  | **0.595**    | 0.55      | 0.519       | 0.579                    |
| **avearge**                | 0.479  | 0.482    | 0.452     | 0.429       | **0.485**                    |


## ChatBaker-SFT (ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸)
ChatBaker-SFTëŠ” ChatBaker-PLMì— SFT (Supervised Fine-Tuning)ë¥¼ ìˆ˜í–‰í•œ ëª¨ë¸ë¡œ, í•™ìŠµì„ ìœ„í•œ íŒŒë¼ë¯¸í„°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

| Model | Global Batch Size | Learning rate | Epochs | Max length | Weight decay | Warmup ratio |
| -- | -- | -- | -- | -- | -- | -- |
| ChatBaker-SFT | 16 | 2e-5 | 3 | 2,048 | 0 | 0.03 |

A100 80G GPU 8ì¥ì„ í•™ìŠµì— ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

| Model | ChatBaker-SFT |
| -- | -- |
| Training time | 20 hours |

### í•™ìŠµ ë°ì´í„°ì…‹

ì§ˆë¬¸/ìš”ì²­ ë° ì´ì— ëŒ€í•œ ì‘ë‹µìœ¼ë¡œ ì´ë£¨ì–´ì§„ Single/Multi-turn í˜•íƒœì˜ ëŒ€í™” ë°ì´í„°ë¥¼ í•™ìŠµì— ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
- ChatBaker-SFTì˜ í•™ìŠµ ë°ì´í„° ê´€ë ¨ ë‚´ìš©ì€ ê³µê°œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ëŒ€ì‹ , ì´ë¯¸ ê³µê°œë˜ì–´ ìˆëŠ” ë‹¤ì–‘í•œ í•œêµ­ì–´ ([evolve-instruct](https://github.com/lcw99/evolve-instruct), [ko-lima-vicuna](https://huggingface.co/datasets/changpt/ko-lima-vicuna), ë“±) ë° ì˜ì–´ ([ShareGPT](https://sharegpt.com), [OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst1), etc.)ì˜ Single/Multi-turn ëŒ€í™” ë°ì´í„°ë¥¼ ì°¸ê³ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í‰ê°€
- ë¹„êµëŒ€ìƒ:
  - [ChatGPT](https://chat.openai.com/): OpenAIê°€ ê³µê°œí•œ ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸ ì„œë¹„ìŠ¤ (GPT-3.5 ë° GPT-4)
  - [Bard](https://bard.google.com/): Googleì´ ê³µê°œí•œ ìƒì„±í˜• ì–¸ì–´ ëª¨ë¸ ì„œë¹„ìŠ¤
  - [KORani-v2-13B](https://huggingface.co/KRAFTON/KORani-v1-13B): LLaMA 13Bì„ í•œêµ­ì–´ ë°ì´í„°ì…‹ìœ¼ë¡œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸
  <!-- - [Vicuna-7b-v1.3](https://huggingface.co/lmsys/vicuna-7b-v1.3): LLaMA 7B ëª¨ë¸ì— ShareGPT 70k ë°ì´í„°ì…‹ìœ¼ë¡œ SFTë¥¼ ìˆ˜í–‰í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ -->
  <!--  - Polyglot-Ko-1.3B-SFT: [Polyglot-Ko-1.3B](https://huggingface.co/EleutherAI/polyglot-ko-1.3b) ëª¨ë¸ì— ChatBakerì™€ ë™ì¼í•œ ë°ì´í„° ë° ì„¸íŒ…ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ -->

| Model | GPT-3.5 | GPT-4 | Bard | KORani | ChatBaker |
| -- | :--: | :--: | :--: | :--: | :--: |
| Params | 175 B | 1,760 B | 137 B | 13 B | 1.3 B |

- í‰ê°€ ë°ì´í„°ì…‹:
  - 10ê°€ì§€ì˜ ì¹´í…Œê³ ë¦¬ì—ì„œ ì´ 121ê°œì˜ íƒœìŠ¤í¬ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤. [dataset](eval/benchmark_set_v2.csv)
- í‰ê°€ ë°©ë²•:
  - GPT-4ë¥¼ í‰ê°€ ìˆ˜ë‹¨ìœ¼ë¡œ ì‚¬ìš©í–ˆê³ , <íƒœìŠ¤í¬, ì§ˆë¬¸, ì‘ë‹µ>ì„ í¬í•¨í•˜ëŠ” [í”„ë¡¬í”„íŠ¸](eval/eval_prompt.yaml)ë¥¼ ì…ë ¥ìœ¼ë¡œ 6ê°€ì§€ í•­ëª©ì— ëŒ€í•´ ê° ë¹„êµëŒ€ìƒì˜ ì‘ë‹µì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.

<figure align="center">
<img src="asset/Ko-Score.png" width="80%" height="80%"/>
<figcaption><b>í•œêµ­ì–´ í‰ê°€ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì‘ë‹µ í’ˆì§ˆ í‰ê°€</b></figcaption>
</figure>

<figure align="center">
<img src="asset/ChatBaker-vs.png" width="70%" height="70%"/>
<figcaption><b>ìƒìš© ì„œë¹„ìŠ¤ì™€ ChatBakerì˜ ì‘ë‹µ ë¹„êµ</b></figcaption>
</figure>


### ëª¨ë¸ ê³µê°œ

- ğŸ¤—[ChatBaker-PLM 1.3B](í—ˆê¹…í˜ì´ìŠ¤ ë§í¬)
- ğŸ¤—[ChatBaker-SFT 1.3B](í—ˆê¹…í˜ì´ìŠ¤ ë§í¬)
- ChatBaker 1.3B < (ê³µê°œì˜ˆì •)

## ì‚¬ìš©ë²•
ë³¸ ë¦¬í¬ì§€í† ë¦¬ì—ëŠ” ê°„ë‹¨í•œ ìƒì„± ì½”ë“œë¥¼ í•¨ê»˜ ì œê³µí•˜ë©°, ì•„ë˜ ëª…ë ¹ì„ í†µí•´ ê´€ë ¨ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ì§ì ‘ ëª¨ë¸ì„ êµ¬ë™í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
$ pip install -r requirements.txt
$ python example_cli.py
```

ê¸°ë³¸ì ìœ¼ë¡œ ë””ë°”ì´ìŠ¤ ì„¤ì •ì„ ìë™ìœ¼ë¡œ ì°¾ë„ë¡ ë˜ì–´ ìˆìœ¼ë©°, CPU ë˜ëŠ” ë©”ëª¨ë¦¬ ì—¬ìœ ê°€ ì¶©ë¶„í•œ GPUë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ ìµœì ì˜ ë””ë°”ì´ìŠ¤ì—ì„œ ë™ì‘í•˜ë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ `--device=cpu` ì˜µì…˜ìœ¼ë¡œ í•­ìƒ CPUì—ì„œ êµ¬ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. M1 ë§¥ë¶ í”„ë¡œì—ì„œëŠ” CPU ì˜µì…˜ìœ¼ë¡œ ë¡œì»¬ êµ¬ë™ì´ ê°€ëŠ¥í•˜ë©°, ë¡œì»¬ êµ¬ë™ì‹œ ì•½ 4GBì •ë„ì˜ ì—¬ìœ  ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ì™¸ì—ë„ ìƒì„±ê³¼ ê´€ë ¨í•œ ì—¬ëŸ¬ ì˜µì…˜ì„ ì§€ì›í•˜ë©° `--help`ë¡œ ë„ì›€ë§ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
$ python example_cli.py --help
```

## í•œê³„ì 
ë‹¤ë¥¸ LLMê³¼ ë§ˆì°¬ê°€ì§€ë¡œ ChatBakerë„ ì—¬ëŸ¬ í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ChatBakerë¥¼ í™œìš©í•  ë•Œ ì´ëŸ¬í•œ í•œê³„ì ë“¤ì„ ê°ì•ˆí•˜ê¸° ë°”ëë‹ˆë‹¤.
- ì–¸ì–´ ëª¨ë¸ì€ [í™˜ê° (Hallucination)](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence))ì´ë¼ëŠ” ê·¼ë³¸ì ì¸ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ì–¸ì–´ ëª¨ë¸ì¸ ChatBakerë„ ì´ëŸ¬í•œ í™˜ê° ë¬¸ì œë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ìƒì„±í•˜ëŠ” ë‚´ìš©ì´ ì‚¬ì‹¤ê³¼ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìì²´ì ìœ¼ë¡œ ChatBaker-SFTì˜ í•™ìŠµ ë°ì´í„°ë¥¼ êµ¬ì¶•í•˜ë©´ì„œ ì¼€ì´ìŠ¤ë¥¼ ìµœëŒ€í•œ ë‹¤ì–‘í™” í–ˆì§€ë§Œ, ë¯¸ì²˜ í¬í•¨í•˜ì§€ ëª»í•œ ì§ˆë¬¸-ì‘ë‹µ ì¼€ì´ìŠ¤ê°€ ì¡´ì¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê¸°ëŒ€í•˜ëŠ” í˜•íƒœì˜ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
- ChatBaker-SFTëŠ” ëœë¤ ìƒ˜í”Œë§ ë°©ì‹ì„ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´, ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ ë§¤ë²ˆ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸/ìš”ì²­ì¸ í”„ë¡¬í”„íŠ¸ì— ë¯¼ê°í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì£¼ì–´ì§„ ì§ˆë¬¸ì— ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í–ˆë”ë¼ë„, ë™ì¼í•œ ë‚´ìš©ì— í‘œí˜„ ë°©ì‹ë§Œ ë‹¤ë¥¸ ì§ˆë¬¸/ìš”ì²­ì— ì „í˜€ ë‹¤ë¥¸ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ChatBakerëŠ” ìƒì„± ê²°ê³¼ì— ë³„ë„ì˜ í•„í„°ë§ì„ ì ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ë„ë•, ì¸ì¢…, ë¬¸í™”, ì„±ë³„, ë‚˜ì´, ì§€ì—­, ì¢…êµ, ì •ì¹˜ì„±í–¥ ë“±ì— ëŒ€í•´ í¸í–¥ì ì´ê±°ë‚˜ ë¶€ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


[//]: # (ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°œë°œì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.)
[//]: # (ì´ëŸ¬í•œ ì¼€ì´ìŠ¤ëŠ” ì‚¬ìš©ì í”¼ë“œë°±ì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ ë³´ì™„í•´ ë‚˜ê°ˆ ê³„íšì…ë‹ˆë‹¤.)


## ë¼ì´ì„¼ìŠ¤
- ë°ì´í„°: ChatBaker-SFT í•™ìŠµì— ShareGPTë¥¼ í¬í•¨í•œ ChatGPTì˜ ë°ì´í„°ë¥¼ ì¼ë¶€ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” OpenAIì— ì˜í•´ ìƒì„±ëœ ë°ì´í„°ì˜ [ì•½ê´€](https://openai.com/policies/terms-of-use)ê³¼ ShareGPTì˜ [Privacy Practices](https://chrome.google.com/webstore/detail/sharegpt-share-your-chatg/daiacboceoaocpibfodeljbdfacokfjb)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
- ëª¨ë¸: [ê³µê°œí•œ ëª¨ë¸](#ëª¨ë¸-ê³µê°œ)ì€ 42dotì˜ R&D ê²°ê³¼ë¬¼ë¡œì„œ, [Apache License 2.0](LICENSE)ë¥¼ ë”°ë¦…ë‹ˆë‹¤.


## ìœ ì˜ì‚¬í•­
ChatBakerë¥¼ í†µí•´ ìƒì„±í•œ ë‚´ìš©ì€ 42dotì˜ ì…ì¥ê³¼ ë¬´ê´€í•˜ë©°, 42dotì€ ì‘ë‹µ ë‚´ìš© ë° ì´ë¡œì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ì œì— ëŒ€í•´ ì±…ì„ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.

## Citation

```
@misc{42dot2023chatbaker,
      title={ChatBaker: Instruction Tuned Large Language Model by 42dot},
      author={Woo-Jong Ryu and Sang-Kil Park and Jinwoo Park and Sungmin Lee and Yongkeun Hwang},
      year={2023},
      url = {https://gitlab.42dot.ai/NLP/hyperai/ChatBaker},
      version = {pre-release},
}
```
